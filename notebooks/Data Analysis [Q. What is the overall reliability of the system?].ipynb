{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience\n",
    "\n",
    "This experience shows an approach used to perform Time-Series data analysis involving Machine Learning for a MSc Thesis project called 'Observing and Controlling Performance in Microservices'.\n",
    "\n",
    "### Context:\n",
    "For this experience, there are values stored in a Time-Series database to be analysed. This values represent metrics extracted from a span data produced by a certain system.\n",
    "\n",
    "### Objective:\n",
    "The objective resides in answer the question related to anomaly detection: \"What is the overall reliability of the system?\". To do this we use two questions:\n",
    "1. How do the request are being handled by a specific service? (Identify services that are experiencing unreliability periods)\n",
    "2. Is there any problem related to the response time?\n",
    "\n",
    "### Features involved:\n",
    "- Status Codes -- (Question 1);\n",
    "- Response time -- (Question 2);\n",
    "\n",
    "### Considerations:\n",
    "- Multiple features to be analyzed;\n",
    "- Possible correlation between features;\n",
    "- Unlabeled data --> (Un)supervised learning;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code bellow was extracted from a module, opentsdb client, presented in Graphy. This function retrieves data from OpenTSDB using the REST API defined by the database developers. To retrieve data, the metric name, start timestamp and end timestamp must be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "opentsdb_address = 'http://127.0.0.1:4242/'\n",
    "api_query = 'api/query'\n",
    "\n",
    "def get_metrics(name: str, start_timestamp: int, end_timestamp: int) -> dict:\n",
    "    \"\"\"\n",
    "    Gets the metrics from OpenTSDB.\n",
    "\n",
    "    :param name: The name of the metrics.\n",
    "    :param start_timestamp: The start unix timestamp of the metric.\n",
    "    :param end_timestamp: The end unix timestamp of the metric.\n",
    "    :return: The metrics as a dictionary if success, None otherwise.\n",
    "    \"\"\"\n",
    "    json_body = {\n",
    "        \"start\": start_timestamp,\n",
    "        \"end\": end_timestamp,\n",
    "        \"queries\": [{\"aggregator\": \"sum\", \"metric\": name},\n",
    "                    {\"aggregator\": \"sum\", \"tsuids\": [\"000001000002000042\", \"000001000002000043\"]}]\n",
    "    }\n",
    "\n",
    "    data = None\n",
    "    try:\n",
    "        response = requests.post(opentsdb_address + api_query, data=json.dumps(json_body),\n",
    "                                 headers={'content-type': 'application/json'})\n",
    "        if response.status_code == 200:\n",
    "            response_text = json.loads(response.text)\n",
    "            if response_text:\n",
    "                data = response_text[0].get('dps', None)\n",
    "        return data\n",
    "    except ConnectionError as ex:\n",
    "        logger.error('{}: {}'.format(type(ex), ex))\n",
    "        sys.exit(status=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to be analyzed\n",
    "\n",
    "The data is gathered from a Time-Series database (OpenTSDB). In this case we get some metrics from this kind of database to perform the analysis.\n",
    "\n",
    "We are using the OUTER JOIN method to merge data from multiple features. This merge method preserves the data points and fills the missing values with NaN (Missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrcis_3: None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-905ba12699cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metrcis_3:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdf_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'status_code.5XX'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mdf_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'response_time_avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "start_timestamp = 1530057600\n",
    "end_timestamp = 1530316800\n",
    "\n",
    "service_name = 'nova-api-cascading'\n",
    "\n",
    "metric_name = 'huawei.status_code.{}.2XX'.format(service_name)\n",
    "metric_name_2 = 'huawei.status_code.{}.4XX'.format(service_name)\n",
    "metric_name_3 = 'huawei.status_code.{}.5XX'.format(service_name)\n",
    "\n",
    "metric_name_4 = 'huawei.response_time_avg.{}'.format(service_name)\n",
    "\n",
    "metrics = get_metrics(metric_name, start_timestamp, end_timestamp)\n",
    "metrics_2 = get_metrics(metric_name_2, start_timestamp, end_timestamp)\n",
    "metrics_3 = get_metrics(metric_name_3, start_timestamp, end_timestamp)\n",
    "metrics_4 = get_metrics(metric_name_4, start_timestamp, end_timestamp)\n",
    "\n",
    "df_1 = pd.DataFrame(metrics.items(), columns=['time', 'status_code.2XX'])\n",
    "df_2 = pd.DataFrame(metrics_2.items(), columns=['time', 'status_code.4XX'])\n",
    "df_3 = pd.DataFrame(metrics_3.items(), columns=['time', 'status_code.5XX'])\n",
    "df_4 = pd.DataFrame(metrics_4.items(), columns=['time', 'response_time_avg'])\n",
    "\n",
    "df = pd.merge(df_1, df_2, how='outer')\n",
    "df = pd.merge(df, df_3, how='outer')\n",
    "df = pd.merge(df, df_4, how='outer')\n",
    "\n",
    "print('\\nData info:\\n{}'.format(df.info()))\n",
    "\n",
    "print('\\nData:\\n{}'.format(df))\n",
    "\n",
    "print('\\nMissing values counting:\\n{}'.format(df.isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.interpolate(method ='linear')\n",
    "\n",
    "df_new = df_new[\"status_code.5XX\"].fillna(0)\n",
    "\n",
    "df_new\n",
    "\n",
    "# print('\\nMissing values counting:\\n{}'.format(df_new.isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "df_copy.plot(x='time', y='status_code.2XX', figsize=(12,6))\n",
    "plt.xlabel('Timestamps')\n",
    "plt.ylabel('Call count')\n",
    "plt.title('Call Count [IN] (MISSING_VALUES)')\n",
    "\n",
    "df_new.plot(x='time', y='status_code.2XX', figsize=(12,6))\n",
    "plt.xlabel('Timestamps')\n",
    "plt.ylabel('Call count')\n",
    "plt.title('Call Count [IN] (COMPLETE)')\n",
    "\n",
    "df_copy.plot(x='time', y='status_code.4XX', figsize=(12,6))\n",
    "plt.xlabel('Timestamps')\n",
    "plt.ylabel('Call count')\n",
    "plt.title('Call Count [OUT] (MISSING_VALUES)')\n",
    "\n",
    "df_new.plot(x='time', y='status_code.4XX', figsize=(12,6))\n",
    "plt.xlabel('Timestamps')\n",
    "plt.ylabel('Call count')\n",
    "plt.title('Call Count [OUT] (COMPLETE)')\n",
    "\n",
    "df_copy.plot(x='time', y='status_code.5XX', figsize=(12,6))\n",
    "plt.xlabel('Timestamps')\n",
    "plt.ylabel('Time (ms)')\n",
    "plt.title('Average Response Time (MISSING_VALUES)')\n",
    "\n",
    "df_new.plot(x='time', y='status_code.5XX', figsize=(12,6))\n",
    "plt.xlabel('Timestamps')\n",
    "plt.ylabel('Time (ms)')\n",
    "plt.title('Average Response Time (COMPLETE)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
